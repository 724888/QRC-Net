# Visual Feature representation
**Name:** Each feature file is named as ```[File ID].npy``` which corresponds to the file ID in [Flickr30K Entities](http://web.engr.illinois.edu/~bplumme2/Flickr30kEntities/).<br/>
**Proposal generation:** We use [Selective Search](https://ivi.fnwi.uva.nl/isis/publications/bibtexbrowser.php?key=UijlingsIJCV2013&bib=all.bib) to generate proposals for each image in [Flickr30K Entities](http://web.engr.illinois.edu/~bplumme2/Flickr30kEntities/). For [Referit Game](http://tamaraberg.com/referitgame/) dataset, we use [Edge Box](https://github.com/pdollar/edges) to generate proposals for each image. We select top ```100``` proposals in each image.<br/>
**Feature extractor:** We apply a [Faster-RCNN](https://github.com/endernewton/tf-faster-rcnn) network pre-trained on PASCAL VOC 2012 for Flickr30K Entities and pre-trained on ImageNet for Referit Game. To extract visual features, we fine-tune the two Faster-RCNN networks on each dataset. The visual feature for each image in these two datasets is represented as a ```100 x 4096``` matrix. Each row corresponds to visual feature (```fc7``` layer of Faster-RCNN) in each proposal bounding box.<br/>
**Fine-tuned visual features:** We are preparing visual features, which will be uploaded soon.